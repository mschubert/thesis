#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage[font=small,labelfont=bf]{caption}

\newcommand*\name[1]{#1}                                                                                                                                                                                                                       
\newcommand*\abbrv[1]{#1}                                                                                                                                                                                                                      
\newcommand*\rpkg[1]{\textit{#1}}                                                                                                                                                                                                              
\newcommand*\file[1]{\textit{#1}}                                                                                                                                                                                                              
\newcommand{\code}[1]{\texttt{#1}}                                                                                                                                                                                                             
                                                                                                                                                                                                                                               
\newcommand*\protein[1]{#1}                                                                                                                                                                                                                    
\newcommand*\gene[1]{\textit{#1}}                                                                                                                                                                                                              
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language british
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Part
Introduction
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
Parts of section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Computational-methods"

\end_inset

 were previously published.
 The text incorporated represents a draft stage of the article below that
 was entirely written by myself:
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard

\series bold
Schubert, M
\series default
 & Iorio, F 
\begin_inset Quotes eld
\end_inset


\shape italic
Exploiting combinatorial patterns in cancer genomic data for personalized
 therapy and new target discovery.
\shape default

\begin_inset Quotes erd
\end_inset

 
\series bold
Pharmacogenomics
\series default
 15, 1943–1946 (2014).
\end_layout

\begin_layout Section
Cancer Biology
\end_layout

\begin_layout Subsection
Significance and epidemiology
\end_layout

\begin_layout Standard
Cancer is a disease of the genes, given rise by changes in the genome that
 mediate malignant transformation and hence uncontrolled growth of a cell
 
\begin_inset CommandInset citation
LatexCommand cite
key "Hanahan2000-is"

\end_inset

.
 The International Agency for Research on Cancer estimates of global incidence
 of cancer to be 12.7 million new cases on 7.6 million cancer deaths based
 on estimates for 182 countries in 2008 
\begin_inset CommandInset citation
LatexCommand cite
key "Ferlay2010-an"

\end_inset

.
 In the United States, it has even surpassed heart disease as the leading
 cause of death in people younger than 85 
\begin_inset CommandInset citation
LatexCommand cite
key "Twombly2005-gg"

\end_inset

.
 Breast cancer is the most abundant form in females, accounting for a total
 of 23% of cases and 14% of deaths.
 For males, the most abundant is lung cancer, comprised of 17% of cases
 and 23% of cancer-related deaths 
\begin_inset CommandInset citation
LatexCommand cite
key "Jemal2011-ku"

\end_inset

.
\end_layout

\begin_layout Standard
Needless to say, the disease is a global health concern and better ways
 of diagnosis and treatment are needed, as well as a better understanding
 of the molecular mechanisms.
\end_layout

\begin_layout Subsection
Causes of genetic variation
\end_layout

\begin_layout Subsubsection
Germline variation
\end_layout

\begin_layout Standard
In the human population, there is natural variation in the genome from one
 individual to another, which gets passed down through generations in the
 process of reproduction.
 Each human being has two copies of their DNA, one passed down from their
 mother and the other passed down from their father.
\begin_inset Foot
status open

\begin_layout Plain Layout
this is excluding mitochondrial DNA that is only passed down the maternal
 lineage 
\begin_inset CommandInset citation
LatexCommand cite
key "Hutchison1974-hh"

\end_inset


\end_layout

\end_inset

 Disregarding of where the copies that an individual actually inherits came
 from, they may harbour the same sequence (that is, the individual is homozygous
 in a given base or gene) or may be different between those so-called alleles
 (that is, the individual is heterozygous).
 This together with our environment is what makes us look different, but
 also what may cause us to be more or less susceptible to a certain disease
 or treatment thereof.
 Since the genes were assembled in the fertilized egg already that afterwards
 underwent cell divisions (in a process called mitosis), all the cells in
 our body in theory harbour the same DNA sequence, with the exception that
 sex cells only contain one copy that was assembled in a cut-and-paste process
 (called meiosis) of the two somatic ones 
\begin_inset CommandInset citation
LatexCommand cite
key "Hotta1966-yq"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Somatic variation
\end_layout

\begin_layout Standard
Should we sequence each cell in an individual, we would not find that all
 of their consecutive bases made up of As, Ts, Cs, and Gs are indeed identical,
 but there is also variation within each individual.
 There may be a change that is common to cells that derive from the same
 parental cell, or a change may have been introduced in a single cell by
 an internal or external process.
 In the former case, we need to realize that the DNA copy mechanism (also
 called DNA replication) that ensures that when a cell splits both its daughter
 cells inherit two full copies of its DNA is not infinitely accurate.
 Rather, this process may introduce reading- (from the ancestral or template
 strand) and writing (the newly synthesised strand) errors.
 In fact, in each cell division there is an average of 100 errors that are
 introduced while copying the each of the three billion bases (times the
 two alleles) that is our genome 
\begin_inset CommandInset citation
LatexCommand cite
key "Kunkel2000-ts,McCulloch2008-wm"

\end_inset

.
\end_layout

\begin_layout Standard
Such an error may manifest itself in multiple ways.
 The replication apparatus (DNA polymerase) may miss the insertion of a
 base or a couple of bases that was in the ancestral in the newly synthesised
 strand, which produces a small deletion, or insert a base that was not
 in the original strand, thereby producing an insertion.
 It may also insert the wrong base, which leads to a substitution 
\begin_inset CommandInset citation
LatexCommand cite
key "Loeb1974-hz"

\end_inset

.
 While discussing these mutational processes one should keep in mind that
 those errors introduced do manifest itself only on one of the two strands
 in an allele, which will lead to a base no longer matching its opposite
 pair as well as if there had been no error.
\end_layout

\begin_layout Subsubsection
Mutations, copy number alterations, and structural variation
\end_layout

\begin_layout Standard
Even when the replication process produced a perfect copy of the ancestral
 strands, there may still be cell-internal or external processes that affect
 the DNA's integrity, 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
latin{e.g.}
\end_layout

\end_inset

 exposure to ultraviolet radiation, , or a host's virus defence system 
\begin_inset CommandInset citation
LatexCommand cite
key "Alexandrov2013-qo"

\end_inset

.
 This could lead to single base exchanges (single nucleotide polymorphisms,
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{SNP}s
\end_layout

\end_inset

), small insertions and deletions (indels), changes in the number of copies
 of DNA segments (copy number alterations or aberrations, CNAs–this can
 happen either on the genome or on extragenomic small chromosomes 
\begin_inset CommandInset citation
LatexCommand cite
key "Jones2012-fc"

\end_inset

), or strand breaking and rejoining at different positions (structural rearrange
ments–
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
latin{e.g.}
\end_layout

\end_inset

 forming gene fusions 
\begin_inset CommandInset citation
LatexCommand cite
key "Nowell1960-rh,Mitelman1997-au,Garnett2012-dk"

\end_inset

).
\end_layout

\begin_layout Subsection
Functional impact of mutations: the central dogma
\begin_inset CommandInset label
LatexCommand label
name "subsec:Consequences"

\end_inset


\end_layout

\begin_layout Standard
A gene that has an erroneous sequence somewhere on the DNA is, by itself,
 not a cause for a cell to alter its function.
 Instead, genes only store the information, like having a template, that
 is required to form an active compound from it.
 Genes can be transcribed in regulatory RNA, or messenger RNA (mRNA; both
 derived from DNA by a process called transcription) that is later used
 by the Ribosome to chain amino acids together to a functional protein in
 a process called translation.
 The process of transcription and translation is referred to the central
 dogma of molecular biology 
\begin_inset CommandInset citation
LatexCommand cite
key "Crick1958-vv"

\end_inset

.
\end_layout

\begin_layout Standard
The path from mRNA to protein may involve additional steps, such as cutting
 out unneeded parts or pasting together different building blocks (splicing),
 or covalently attaching sugars or other chemical groups (post-translational
 modifications) to yield the functional protein and/or to regulate its activity
 
\begin_inset CommandInset citation
LatexCommand cite
key "Crick1958-vv"

\end_inset

.
 Proteins are involved in the transduction of a signal from a molecular
 cue binding to a receptor on a cell's surface is how a cell responds to
 changes in its environment.
 In turn, this signal is relayed through the network of kinases and phosphatases
\begin_inset Foot
status open

\begin_layout Plain Layout
there are other chemical modifications, but those are the best studied
\end_layout

\end_inset

 until it reaches the terminal nodes that are the transcription factors,
 acting in conjunction with polymerase III and other co-factors to initiate
 changes in gene expression.
 Those genes are in turn transcribed into RNA, and if they are protein-coding
 consequently translated into those.
\end_layout

\begin_layout Standard
Take, for instance, a protein involved in relaying a signal from the cell
 surface, such as a signal to grow and divide, to another protein that in
 turn activates some other proteins which ultimately induces the expression
 of genes that are needed for the cell's replication machinery.
 These signals are usually relayed by post-translational modifications (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{PTMs}
\end_layout

\end_inset

) from one protein to another.
 One of the best-studied processes is phosphorylation (the addition of a
 phosphate group - proteins that do that are called kinases, the ones that
 remove phosphatases) of Serines or Threonines.
 These are amino acids with an OH group in their side chain and are thus
 susceptible to it 
\begin_inset CommandInset citation
LatexCommand cite
key "Burnett1954-bw"

\end_inset

.
 This protein now may be affected by a mutation so that it no longer waits
 for an upstream signal to transduce, but sends the downstream signal to
 grow and divide irrespective of what the upstream input is.
 One such example is the well-known 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gene{BRAF^{V600E}}
\end_layout

\end_inset

 mutation, where a Valine on position 600 (the 600th amino acid) is replaced
 by Glutamic Acid 
\begin_inset CommandInset citation
LatexCommand cite
key "Zecchin2013-fn"

\end_inset

.
\end_layout

\begin_layout Standard
Genes that are relevant for cancer development and progression have long
 been classified in Oncogenes and Tumour Suppressor Genes 
\begin_inset CommandInset citation
LatexCommand cite
key "Croce2008-bn"

\end_inset

.
 In broad terms, this classification represents the following: does a mutation
 introduce a gene function that was not there before, or it loses sensitivity
 to an inhibitory signal that kept it in check, this gene is called an Oncogene
 in its active (mutated) form, or Proto-Oncogene in its wild-type form;
 conversely, if a mutation causes a gene to lose its function as e.g.
 a negative regulator of cell growth, it is called a Tumour Suppressor Gene.
 The first Tumour Suppressor Gene that has been found was 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gene{TP53}
\end_layout

\end_inset

 in 1979, now termed 
\begin_inset Quotes eld
\end_inset

guardian of the genome
\begin_inset Quotes erd
\end_inset

 whose protein is involved in numerous functions maintaining DNA integrity,
 managing DNA repair, and causing apoptosis or senescence of the former
 fail 
\begin_inset CommandInset citation
LatexCommand cite
key "Levine2009-lo"

\end_inset

.
 More recently, mutations that actively contribute to either development
 of progression of a cancer have been called drivers, while the mutations
 introduced by e.g.
 a faulty DNA replication machinery (that a cancer may have caused) that
 bear no functional impact on the cell are called passenger mutations.
 Driver genes are usually either activated Oncogenes or Tumour suppressor
 genes, but may also have both functions 
\begin_inset CommandInset citation
LatexCommand cite
key "Vogelstein2004-mx"

\end_inset

.
\end_layout

\begin_layout Subsection
Malignant transformation
\end_layout

\begin_layout Standard
Mutagenic driving forces 
\begin_inset CommandInset citation
LatexCommand cite
key "Alexandrov2013-qo"

\end_inset

 are not only all around but also inside us (as exemplified by the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gene{APOBEC}
\end_layout

\end_inset

 virus defence).
 However, most cells do not start to divide uncontrollably, even if they
 acquire a driver mutation.
 For instance, it has been shown that in healthy skin there is a high number
 of potential driver mutation that pre-exist without cancer ever developing
 from them 
\begin_inset CommandInset citation
LatexCommand cite
key "Martincorena2015-iw"

\end_inset

.
 For a cell to develop into a malignant tumour, it requires multiple 
\begin_inset Quotes eld
\end_inset

hits
\begin_inset Quotes erd
\end_inset

 that transform it into a truly malignant state.
 The mutations and mechanisms but which it acquires those properties are
 different from cancer to cancer, yet the biological processes it needs
 to modify are remarkable similar 
\begin_inset CommandInset citation
LatexCommand cite
key "Hanahan2000-is,Hanahan2012-im"

\end_inset

:
\end_layout

\begin_layout Itemize
Self-sufficiency in growth signals: being able to grow and divide without
 external cues present
\end_layout

\begin_layout Itemize
Insensitivity to anti-growth signals: being able to grow despite usual inhibitor
y mechanisms
\end_layout

\begin_layout Itemize
Evading apoptosis: eliminating checks and bounds that make an abnormal cell
 commit suicide
\end_layout

\begin_layout Itemize
Limitless replicative potential: replenishing telomeres that grow shorter
 after each division 
\end_layout

\begin_layout Itemize
Sustained angiogenesis: promoting blood vessel growth to get an increased
 supply in nutrients
\end_layout

\begin_layout Itemize
Tissue invasion and metastasis: breaking the local confinement of the tissue
 it first arose
\end_layout

\begin_layout Itemize
Avoiding immune destruction: not being targeted by cytotoxic T-lymphocytes
\end_layout

\begin_layout Itemize
Deregulating cellular energetics: still producing energy with a lack of
 oxygen
\end_layout

\begin_layout Subsection
Tumour heterogeneity
\end_layout

\begin_layout Standard
Cells in a tumour are not homogeneous, but the latter should rather be seen
 as an evolutionary process of diverse clones that compete for a growth
 advantage subjected to positive and negative selection.
 This has implications for cancer growth as well as therapy, and hence assessing
 this heterogeneity has become an important research topic 
\begin_inset CommandInset citation
LatexCommand cite
key "Heppner1983-sw,Alizadeh2015-bz"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
cc-by timeline figure?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
However, there are a couple of challenges when trying to assess the whole
 genetic diversity of a sample.
 It is important to take it not only in one place, but either homogenise
 the tissue or selectively take small samples in different subsections.
 Another challenge is that for detecting very minor frequencies, one needs
 to read the genome many times over and be sure that the resulting variants
 are not only due to errors in this process, or any other by which the sample
 is treated after acquisition.
\end_layout

\begin_layout Section
Therapeutic interventions
\end_layout

\begin_layout Subsection
The therapeutic window
\end_layout

\begin_layout Standard
Within a therapeutic intervention, our goal is to selectively treat (or
 kill) the diseased cells while not impacting the normal function of other
 cells in the body.
 If at first we assume that a treatment can be delivered to all cells of
 the body in the same amount, the question is whether the impact it has
 is impacting the cells we want to act on more than all the other cells
 we want to impact as little as possible.
 If we take the simple example of killing cells, we want a drug that kills
 all the bad cells and leaves the good cells alone.
 Hence, an effective drug will work on the bad cells at a lower concentration
 than on the good ones.
 If the concentration is too high, it will undoubtedly affect other cells
 as well.
 This range of concentration, where a given drug already acts on the target
 cells but does not confer toxicity to other cells is called the therapeutic
 window.
 The broader it is, the easier it is to work with this drug.
\end_layout

\begin_layout Standard
Elaborating on our simplification, it is of course not the case that an
 administered compound will be available to all cells at the same concentration.
 Instead 
\begin_inset CommandInset citation
LatexCommand cite
key "Ruiz-Garcia2008-ep"

\end_inset

, it first needs to reach the bloodstream (which includes uptake and resorption,
 then modification in the liver and pancreas if taken orally), then be distribut
ed by the flow of blood into all the capillaries (which the exception of
 the brain that has an additional barrier), until finally cells are able
 to absorb it.
 As a rule of thumb whether a drug can be orally absorbed or not, a common
 measure is 
\begin_inset Quotes eld
\end_inset

Lipinsky's Rule of Fives
\begin_inset Quotes erd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Lipinski2012-cl"

\end_inset

, that states that an orally effective drug has no more than one violation
 of (1) no more than five hydrogen bond donors, (2) no more than ten hydrogen
 bind acceptors, (3) a molecular mass less than 500 daltons, (4) an octanol-wate
r distribution coefficient (
\begin_inset Formula $logP$
\end_inset

) of less than five.
\begin_inset Foot
status open

\begin_layout Plain Layout
Note that these are only four and not five rules.
 The 
\begin_inset Quotes eld
\end_inset

five
\begin_inset Quotes erd
\end_inset

 in the rule's name stems from the components being multiples of five, not
 that there are five rules
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Cytotoxic drugs
\end_layout

\begin_layout Standard
The easiest way to kill cancer cells is to expose them to a compound that
 is generally toxic to cells.
 While this is expected to have a negative impact on all cells, there are
 certain properties of cancer cells that make them more susceptible.
 One such property is that they grow more actively than most other cells,
 and so a therapeutic window exists for compounds that interfere with cell
 growth, as is the case for most chemotherapy.
 This could be DNA synthesis (Cisplatin or Carboplatin), microtubule disassembly
 (Paclitaxel and more generally Taxol-based compounds), or others 
\begin_inset CommandInset citation
LatexCommand cite
key "Skeel2011-rj"

\end_inset

.
\end_layout

\begin_layout Subsection
Targeted therapies
\end_layout

\begin_layout Standard
\begin_inset CommandInset label
LatexCommand label
name "subsec:targeted-therapies"

\end_inset

A recurrent theme of cancer development and progression is the aberrant
 activation of specific molecular cues in cell signalling.
 An example of this is the well-known 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gene{BRAF^{V600E}}
\end_layout

\end_inset

 mutation, already mentioned in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Consequences"

\end_inset

.
 But there are many more instances where a mutation in a gene yields a gene
 product that is abnormally active- or inactive.
 This often includes members of the MAP kinase pathway (like EGFR, RAS,
 RAF, MEK, or ERK), but frequently also other proteins and pathways that
 confer a selective advantage in a given context.
 An important aspect in that regard is the concept of oncogene addiction:
 Once a cell, or a population of cells, suffers a molecular lesion that
 causes aberrant signalling, the cell (or cells) become dependent on exactly
 that signal.
 Turn it off, and those cells are likely to die 
\begin_inset CommandInset citation
LatexCommand cite
key "Weinstein2002-iw"

\end_inset

.
\end_layout

\begin_layout Standard
This has an important implication for cancer therapy: if we are able to
 find (or design) a compound that specifically turns off one of those abnormally
 active proteins, we can kill cells that have it active.
 In example of the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gene{BRAF^{V600E}}
\end_layout

\end_inset

 mutation, computational chemists indeed designed and developed a small-molecule
 inhibitor called Plexicon (more specifically, PLX4720 or nowadays called
 Vemurafenib) that proved to bind the mutated version of the BRAF protein
 with a much higher affinity than the one found in wild-type cells.
 This, in some ways, could be considered the perfect drug for cancer therapy,
 because it has it has favourable uptake in the body and afterwards the
 therapeutic window is much larger compared to other compounds due to this
 difference in binding affinity 
\begin_inset CommandInset citation
LatexCommand cite
key "Chapman2011-jl"

\end_inset

.
\end_layout

\begin_layout Standard
There are, however, many other kinase inhibitors as well as antibodies that
 specifically target a protein to abrogate its activity.
\end_layout

\begin_layout Subsection
Development of resistance
\end_layout

\begin_layout Standard
Unfortunately, targeted therapies often can not kill all cells before they
 acquire a resistance mechanism to the treatment, or a sub-population of
 cells were resistant to begin with and then outgrow their competitors.
 This is one of the reasons why targeting mutations in driver genes is a
 good start, but it needs to be augmented with knowledge of the dynamic
 changes mutations induce in the cellular signalling network and the evolutionar
y paths for a cell to respond.
\end_layout

\begin_layout Standard
Let us revisit one of the most well-known examples in targeted therapies,
 the inhibition of 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gene{BRAF^{V600E}}
\end_layout

\end_inset

 mutants.
 This example of targeted therapy works with the intended effect in such
 that it kills cancer cells to an extent that makes multiple from the outside
 clearly visible tumours completely disappear for months 
\begin_inset CommandInset citation
LatexCommand cite
key "Chapman2011-jl"

\end_inset

, which could be hailed as a success for identifying a target and rationally
 designing an inhibitor that abrogates oncogenic signalling.
 However, there was one drawback: after a couple more weeks past the initial
 success the tumour cells were able to overcome the effects of the inhibitor,
 leading to the recurrence of tumours that the patient later died from.
\end_layout

\begin_layout Standard
This, together with multiple other examples, proved to show that targeted
 therapies work for a while, but they are, in a lot of cases, unable to
 permanently suppress tumour growth.
 But how does this work? In order for a tumour to regrow, there need to
 be some cancerous cells left alive after treatment, as this rapid regrowth
 of mass can not be explained by an independent inception.
 Hence, some cells must have survived the process of therapy 
\begin_inset CommandInset citation
LatexCommand cite
key "Heppner1983-sw,Reya2001-ay"

\end_inset

.
\end_layout

\begin_layout Standard
Many distinct strategies have been suggested to more effectively kill cancer
 cells, most notably the combination of a MEK and BRAF inhibitor in melanoma
 
\begin_inset CommandInset citation
LatexCommand cite
key "Long2014-uy"

\end_inset

.
 In fact, the very nature of killing off the majority of cells and pushing
 the rest through an evolutionary bottleneck has been suggested as a basis
 for designing therapies taking into account those temporal patterns in
 adaptation 
\begin_inset CommandInset citation
LatexCommand cite
key "Hata2016-cg"

\end_inset

 
\begin_inset Note Note
status open

\begin_layout Plain Layout
ref: zhao cell 2016
\end_layout

\end_inset

.
\end_layout

\begin_layout Section
Disease models
\end_layout

\begin_layout Subsection
Rationale
\end_layout

\begin_layout Standard
It is easy to argue that in order to find better cancer treatments, we first
 need to understand better the molecular mechanisms that drive it.
 This is especially true because the mechanisms involved from the inception
 of cancer up the its progression and spreading are in fact molecular mechanisms
 that have spun out of the normal biological control that cells of an organism
 exert on each other.
 In order to improve our understanding, it is required to collect data about
 the different types, stages, and treatments of the disease.
\end_layout

\begin_layout Standard
This poses a problem: it is not possible to perform all of the assays required
 on the actual patients.
 There is just no justification for a patient to undergo surgery if we want
 to know if protein A interacts with protein B.
 Also, we can not try new treatments without a strong indication that this
 might be the best known possibility of curing a patient, as this would
 be highly unethical.
 It follows that there is a requirement for some biological system that
 mirrors the disease while, at the same time, is easy to handle in the laborator
y.
 In choosing such a system, the points mentioned involve a trade-off: one
 that mirrors the disease perfectly and is easy to handle does not exist,
 but there are multiple systems (outlined in the sections below) that are
 closer to one or the other.
 Which one to use must be decided in each experiment individually - considering
 its goals, effort, conclusiveness and applicability to the question studied.
\end_layout

\begin_layout Standard
If these disease models provide a strong indication that a certain treatment
 approach is truly beneficial to a certain patient or patient group, this
 needs to be thoroughly tested to make sure that those indications previously
 shown using a model system - that are known to mirror a lot of aspects
 of the actual disease, but never all - actually hold in humans as well
 
\begin_inset CommandInset citation
LatexCommand cite
key "Fields2005-tb"

\end_inset

.
\end_layout

\begin_layout Subsection
Cell lines
\end_layout

\begin_layout Standard
One of the easiest model systems that provide a reasonably accurate mirror
 of a lot of the biology involved in the disease are cell lines, which is
 basically taking a number of cells from a tumour, and growing them in a
 petri dish for multiple generations (passages).
 An advantage of this method is that the biological material that assays
 can be performed on is virtually unlimited, easy to produce and maintain.
 This is because cells grow in the dishes as long as they are supplied with
 nutrients and potentially growth factors or cytokines, while still reflecting
 a lot of the properties that cells in a tumour would.
 However, by passaging cells consecutively in petri dishes for many generations,
 the evolutionary pressure that they are selected by is essentially the
 growth rate on the dish, which will not reflect the forces one would find
 in a real tumour.
 In fact, the fastest growing clone will outcompete all others in a couple
 of generations - which gives a relatively uniform molecular phenotype across
 all cells, but in turn also loses the heterogeneity found in a primary
 sample.
\end_layout

\begin_layout Standard
Today, there is a multitude of cell lines available from commercial suppliers.
 The maybe best-known example is that of the HeLa cell line 
\begin_inset CommandInset citation
LatexCommand cite
key "Gey1952-qc"

\end_inset

 that was derived from a patient of cervical cancer in 1951, named Henrietta
 Lacks.
 This cell line, however, considering how long it has been kept in culture
 as well as its high mutation rate, has produced a genotype that no longer
 resembles primary cancer samples in many ways.
 One property is that a normal human cell has two copies of the genome (the
 two alleles), whereas HeLa cells have four copies, and its genome revealed
 more extensive aberrations 
\begin_inset CommandInset citation
LatexCommand cite
key "Landry2013-sk"

\end_inset

.
 In most cases however, experimentally used cell lines are more closely
 tied their origin: they have, albeit with aberrations, a genome that resembles
 primary tumours and they hence in many ways still resemble their tissue
 of origin in molecular terms.
\end_layout

\begin_layout Standard
However, there are biological dynamics involved in a real tumour that can
 not be recapitulated by cell lines, like their interactions with other
 cells (especially immune cells) or with their surroundings (the extracellular
 matrix).
 Also, their number is limited.
 With the approximately 1,000 cell lines that the Genomics of Drug Sensitivity
 in Cancer (GDSC, cf.
 section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:GDSC"

\end_inset

) screened for compound sensitivity 
\begin_inset CommandInset citation
LatexCommand cite
key "Iorio2016-gh"

\end_inset

, it is time to think about how many more cell lines would be needed to
 gain enough statistical power for the high number of rare mutations and
 whether the required amount of diversity can theoretically be generated
 with cell lines 
\begin_inset CommandInset citation
LatexCommand cite
key "Francies2015-fs"

\end_inset

.
 One way to resolve this issue could be organoid cultures: these are small
 assemblies of primary cells taken out of a tumour and grown in matrigel,
 where the spatial separation of mini-cultures retains much of the tumour
 heterogeneity 
\begin_inset CommandInset citation
LatexCommand cite
key "Sachs2014-dz"

\end_inset

.
 Because of these properties, they could advance 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
latin{in silico}
\end_layout

\end_inset

 cancer screening in a way that is not possible with other platforms 
\begin_inset CommandInset citation
LatexCommand cite
key "Francies2015-fs"

\end_inset

.
\end_layout

\begin_layout Subsection
Animal models
\end_layout

\begin_layout Standard
For some kinds of experiments, it is necessary to model the effects on a
 whole organism.
 For this purpose animals have long been used, from a simple multicellular
 worm (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
species{Caenorhabdilis elegans}
\end_layout

\end_inset

, mostly for development and its simple central nervous system) to frogs
 (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
species{Xenopus}
\end_layout

\end_inset

, for induced pluripotency), and mammals (mice, rats, and chimps; often
 for diseases).
 Just as the complexity of these organisms increases, they also mirror more
 closely aspects of human physiology.
 However, experiments performed in higher organisms also require more time,
 they are more difficult (and expensive) to set up, and there are ethical
 concerns on keeping, handling, and killing animals for the purpose of ultimatel
y saving human lives.
\end_layout

\begin_layout Standard
In terms of cancer, looking at the number of articles published about a
 specific molecular mechanism or the detailed characterisation of a compound
 and its usability as a drug, mice seem to be considered a reasonable trade-off
 between providing a close enough match of human biology and being not too
 difficult to keep 
\begin_inset CommandInset citation
LatexCommand cite
key "Fields2005-tb"

\end_inset

.
 To gain insights, a mouse's genome can be engineered to include for instance
 a mutated version of a human gene that is known to induce the formation
 of tumours 
\begin_inset CommandInset citation
LatexCommand cite
key "Talmadge2007-tr"

\end_inset

, or can be inoculated with cancerous cells derived from either a cell line
 or a patient 
\begin_inset CommandInset citation
LatexCommand cite
key "Fogh2014-ah"

\end_inset

.
 Mouse models have taught us how cancerous cells influence and modify the
 microenvironment around them and how the cells can sustain themselves and
 grow, attract the formation of blood vessels, and ultimately metastasise
 
\begin_inset CommandInset citation
LatexCommand cite
key "Talmadge2007-tr"

\end_inset

.
\end_layout

\begin_layout Section
Molecular data types and assays
\end_layout

\begin_layout Subsection
Role of molecular data
\end_layout

\begin_layout Standard
One of the issues of both understanding as well as preventing or treating
 cancer development and progression is that it is a process with such complexity
 that a simple observation of patients with the disease will not suffice
 to come up with effective models of disease inception and progression,
 or treatments for that matter.
 Fortunately, we have got a battery of tests available, quantifying different
 molecular aspects of a biological sample.
 Examples of these data include the sequence, structure, and modification
 of DNA, but also the expression of RNA or proteins, including modifications.
 These different layers, able to quantify different projections of a cell's
 state, have provided us with an unprecedented opportunity to truly understand
 many molecular mechanisms that govern the processes active in both a normal
 and a diseased cell, and the differences between them.
\end_layout

\begin_layout Subsection
DNA
\end_layout

\begin_layout Standard
When Frederick Sanger discovered 
\begin_inset CommandInset citation
LatexCommand cite
key "Sanger1977-mb"

\end_inset

 that one could read DNA by supplying a minor fraction of di-deoxynucleotides
 in addition to labelled deoxynucleotides that are normally incorporated
 into DNA during replication, in turn halting the replication chain and
 revealing the sequence, it was soon clear that this technology would revolution
ise biology and medicine.
 Further incremental improvements and then the switch to next-generation
 sequencing has enabled the scientific community to read DNA on an unprecedented
 scale 
\begin_inset CommandInset citation
LatexCommand cite
key "Schuster2008-pe"

\end_inset

, with the implication that the genome of individual (cancer) patients could
 soon be used to decide upon optimal treatment of each individual 
\begin_inset CommandInset citation
LatexCommand cite
key "McDermott2015-sn"

\end_inset

.
\end_layout

\begin_layout Subsection
RNA
\begin_inset CommandInset label
LatexCommand label
name "subsec:assay_RNA"

\end_inset


\end_layout

\begin_layout Standard
All healthy cells contain roughly the same genome, yet the functions they
 perform in the body is vastly different.
 This is why in contrast to DNA, the RNA that is transcribed represents
 more the state a cell is currently in and functions that need to be performed
 at a given time and in a given context.
 It can hence be argued that the sum of RNAs (the transcriptome), or more
 specifically mRNAs provides an overview of the state a cell is currently
 in.
 Measuring those RNAs will allow us to get a picture of the processes going
 on in a cell at a given time.
 The two ways by which this is usually done are either microarrays or RNA
 sequencing, as outlined below.
\end_layout

\begin_layout Subsubsection
Microarrays
\end_layout

\begin_layout Standard
The classic way to measure RNA expression is using microarrays 
\begin_inset CommandInset citation
LatexCommand cite
key "Brown1999-mc,Debouck1999-ec"

\end_inset

.
 These are, in the simplest case, a carrier matrix (glass can be used but
 the more recent chips use a polymer matrix) that has fixed single-stranded
 oligonucleotides spotted on them.
 From our sample, we would then extract and clean the RNA while simultaneously
 degrading any DNA that it contains, and label the RNA either with one dye
 
\begin_inset CommandInset citation
LatexCommand cite
key "Gohlmann2009-ac,Du2008-sb"

\end_inset

 (if we want to quantify the expression levels of transcripts in a given
 sample) or two different dyes 
\begin_inset CommandInset citation
LatexCommand cite
key "Shalon1996-pq"

\end_inset

 (if we want to quantify the difference between two samples).
 Such fluorescent dyes used are e.g.
 Cy3 and Cy5, that emit light in the green and red wave lengths upon stimulation
, respectively.
 Note that if the technical reproducibility of the platform is good enough,
 it is also possible to compare conditions by using two different arrays
 where we measure each sample individually and then compare the outcome.
 - A technique that has been favoured by companies like Affymetrix as it
 allowed chips at much higher density and the comparison between each sample
 in a control- and in a experimental condition, as well as between them.
\end_layout

\begin_layout Standard
An obvious drawback of this technology is that we need to know in advance
 which oligonucleotides to spot, so in turn which genes we are looking for.
 There needs to be different chips for different organisms, depending on
 the gene sequences that they carry.
 This selection of genes that we look at can of course introduce bias, in
 such that we can't look for transcripts that we don't know exist, but also
 we might focus on transcripts and isoforms that we think are important
 before carrying out an experiment.
 Another possible issue is their detection threshold.
 As the readout is fluorescence based and there will always be a base-line
 level of it, and it is hard to quantify the amount of RNA bound on a spot
 of the total number of molecules are so low that a few molecules do not
 significantly change the readout.
 Turning this argument around, RNA binding to spots also has its point of
 saturation, where it does not matter if there is more RNA present or not
 once all probes bind to their complementary sequence and thus produce a
 signal 
\begin_inset CommandInset citation
LatexCommand cite
key "Duggan1999-eu"

\end_inset

.
\end_layout

\begin_layout Subsubsection
RNA sequencing
\end_layout

\begin_layout Standard
An alternative approach that has become more popular recently with the falling
 costs of DNA sequencing is to apply this technology to RNA as well 
\begin_inset CommandInset citation
LatexCommand cite
key "Marioni2008-lb,Wang2009-ge"

\end_inset

.
 In this case, we can use the RNA that we isolated from a sample, reverse-transc
ribe it into DNA, and sequence the DNA like we would normally.
 This has got the advantage that it can be used even if there is no genome
 sequence or chip available and as a consequence we are also not biasing
 our selection of genes by previously knowing what to look at 
\begin_inset CommandInset citation
LatexCommand cite
key "Trapnell2010-le"

\end_inset

, with the exception of sections in the RNA that can be more or easily transcrib
ed into DNA (like GC-rich regions that also pose challenges for sequencing).
 Another advantage is that the dynamic range of this technology (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
latin{i.e.}
\end_layout

\end_inset

, the differences in transcript numbers it can detect) is much higher than
 it is for microarrays, both on the lower as well as on the upper bound:
 we can detect a single read, but also having a lot of reads won't saturate
 our signal the same way that spots on the microarray do (although if a
 large proportion of the reads is from a highly abundant molecule, this
 will decrease sensitivity for detecting other RNAs).
\end_layout

\begin_layout Standard
The way RNA-seq quantification 
\begin_inset CommandInset citation
LatexCommand cite
key "Mortazavi2008-lh,Li2011-zi"

\end_inset

 is usually done is to align the reads to a known genome, allowing gaps
 in the alignment for splicing and differential use of exons 
\begin_inset CommandInset citation
LatexCommand cite
key "Trapnell2012-ds"

\end_inset

.
 The transcription level of a gene, transcript or exon are then quantified
 by how many reads align to the corresponding section in the genome.
 As this is computationally very expensive, there have been efforts recently
 to get around performing the alignment step by k-mer counting and so-called
 pseudo-alignments.
 Methods for the latter include Sailfish 
\begin_inset CommandInset citation
LatexCommand cite
key "Patro2014-wf"

\end_inset

, Salmon 
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
target "https://github.com/COMBINE-lab/salmon"

\end_inset


\end_layout

\end_inset

, or Kallisto 
\begin_inset CommandInset citation
LatexCommand cite
key "Bray2016-gx"

\end_inset

.
\end_layout

\begin_layout Standard
The data produced by RNA-sequencing is different to the one from microarrays,
 as it is based on read numbers that thus counts (so discrete data) instead
 of the continuous fluorescence signal that microarrays provide.
 These counts are negatively binomially distributed 
\begin_inset CommandInset citation
LatexCommand cite
key "Anders2010-pd"

\end_inset

, and require specialised software packages to call e.g.
 differential expression like 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rpkg{edgeR}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Robinson2010-uc"

\end_inset

, 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rpkg{DEseq}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Anders2010-pd"

\end_inset

 and 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rpkg{DEseq2}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Love2014-dr,Love2014-la"

\end_inset

, or transformation before they can be used in standard linear modelling
 techniques, for instance provided by 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
code{voom}
\end_layout

\end_inset

 in the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rpkg{limma}
\end_layout

\end_inset

 package 
\begin_inset CommandInset citation
LatexCommand cite
key "Law2014-cf"

\end_inset

.
\end_layout

\begin_layout Subsection
Proteins and phosphorylation
\end_layout

\begin_layout Standard
It can easily be argued that in order to get an appropriate picture of what
 goes on in a cell it would be better to look at the proteins that perform
 most functions, as opposed to the mRNA levels of genes.
 The latter will in many cases be translated into proteins that then exert
 their activity, yet mRNA measurements are one more step removed from the
 functional process than proteins, and measuring post-translational modification
s (PTMs) that modify activity already gives us a lot of functional information
 - as long as we know how to interpret it.
\end_layout

\begin_layout Standard
Taking these facts together, we might want to look at proteins instead of
 gene expression.
 Yet, gene expression is a lot cheaper and easier to measure, as well as
 providing more coverage than the proteomic methods currently can.
 Also, the publicly available gene expression data far exceeds the one of
 proteomic data.
 There are different experimental methods for quantifying proteins and their
 state, the most well-known are listed below.
 This thesis, however, is focussed on gene expression.
\end_layout

\begin_layout Subsubsection
Reverse-Phase Protein Arrays (RPPA)
\end_layout

\begin_layout Standard
In this method 
\begin_inset CommandInset citation
LatexCommand cite
key "Tibes2006-fg"

\end_inset

, there is an array of spotted antibodies, similar to the nucleic acids
 on a microarray.
 A labelled cell lysate (or other sample) is incubated with the antibodies,
 and we can quantify the amount of the proteins (or phospho-proteins) correspond
ing to each antibody afterwards.
 In contrast to microarrays, however, this is relatively low throughput
 as antibodies can not be as readily synthesized as nucleic acids.
\end_layout

\begin_layout Subsubsection
Mass spectrometry
\end_layout

\begin_layout Standard
Mass spectrometry 
\begin_inset CommandInset citation
LatexCommand cite
key "Domon2006-au,Bensimon2012-iy"

\end_inset

 is based on fragmenting proteins into peptides that are then ionized and
 sprayed into an electrical field in a vacuum tube, where their mass-to-charge
 ratio causes them to behave in a certain way.
 For instance, in Time of Flight (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{TOF}
\end_layout

\end_inset

) instruments, the electrical field is used to accelerate the peptides;
 the force that accelerates them is then proportional to their charge, and
 their inertia to their mass–hence the time it takes to reaches the detector
 is proportional to the ratio of the two.
\end_layout

\begin_layout Standard
For more complex samples, there are too many peptides to detect at any given
 time, so the Mass Spectrometry is often coupled with another technology
 that first separates proteins contained in a sample using some other property
 (e.g.
 their hydrophilicity/hydrophobicity) in columns of gas (gas chromatography,
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{GC}
\end_layout

\end_inset

) or liquid (high performance liquid chromatography, 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{HPLC}
\end_layout

\end_inset

).
\end_layout

\begin_layout Section
Data sets
\end_layout

\begin_layout Subsection
Public gene expression repositories
\end_layout

\begin_layout Standard
There are two major repositories of gene expression experiments using microarray
s, the Gene Expression Omnibus (GEO) 
\begin_inset CommandInset citation
LatexCommand cite
key "Barrett2007-dy,Barrett2009-nh"

\end_inset

 at the National Institutes of Biotechnology Information (NCBI) and ArrayExpress
 
\begin_inset CommandInset citation
LatexCommand cite
key "Parkinson2007-bf,Parkinson2009-ej"

\end_inset

 at the European Bioinformatics institute.
 The reporting standards defined in the Minimal Information about a Microarray
 Experiment (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{MIAME}
\end_layout

\end_inset

) 
\begin_inset CommandInset citation
LatexCommand cite
key "Brazma2001-ro"

\end_inset

, played a pivotal role to ensure that experiments where one could not only
 measure one gene but the entire transcriptome remained interpretable.
 Both of these are synchronised, which means that submissions one will be
 imported and made available on the other as well.
 More recently, ArrayExpress also started collecting RNA-seq and ChIP-seq
 experiments.
\end_layout

\begin_layout Subsection
Gene sets and pathways
\end_layout

\begin_layout Standard
With about 22,000 human genes whose transcription can be all measured simultaneo
usly using the methods described in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:assay_RNA"

\end_inset

, it is important to put genes into functional groups for several reasons:
 (1) groups of higher level processes are more interpretable, (2) gene level
 measurements in microarrays (and to a lesser extent RNA-sequencing) are
 inherently noisy and the more measurements we combine the clearer the signal
 gets, and (3) it may be possible to solve statistical problems where the
 number of observations per sample is greater than the number of samples.
\end_layout

\begin_layout Standard
There are multiple databases available that link gene sets into function
 groups.
 Some of the most well-known are listed below, but there are others.
\end_layout

\begin_layout Subsubsection
Gene Ontology
\end_layout

\begin_layout Standard
Gene Ontology (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{GO}
\end_layout

\end_inset

) 
\begin_inset CommandInset citation
LatexCommand cite
key "Ashburner2000-xl,Gene_Ontology_Consortium2004-sn"

\end_inset

 is 
\begin_inset Quotes eld
\end_inset

a major bioinformatics initiative to develop a computational representation
 of our evolving knowledge of how genes encode biological functions at the
 molecular, cellular and tissue system levels
\begin_inset Quotes erd
\end_inset

.
 It has encoded over 40,000 biological concepts based on experiments reported
 in over 100,000 publications according to its web portal at 
\begin_inset CommandInset href
LatexCommand href
target "http://geneontology.org/"

\end_inset

.
\end_layout

\begin_layout Subsubsection
KEGG
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{KEGG}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Kanehisa2000-mp"

\end_inset

 was one of the first pathway databases.
 To provide an idea of how widely it was (and still is) used, Google Scholar
 (query 25th February 2016) reported 6863 publications that cited the original
 article.
 However, in 2011 the platform went commercial, allowing access only via
 a subscription-based portal.
\begin_inset Foot
status open

\begin_layout Plain Layout
http://www.pathway.jp/
\end_layout

\end_inset

 While the authors removed public access also to earlier versions of the
 database, its pre-commercial license (OICR by Pathway Solutions, Inc.) allowed
 it to still be used.
 It will, however, not receive any more updates.
\end_layout

\begin_layout Subsubsection
Reactome
\end_layout

\begin_layout Standard
Reactome 
\begin_inset CommandInset citation
LatexCommand cite
key "Croft2011-po"

\end_inset

 is a 
\begin_inset Quotes eld
\end_inset

a free, open-source, curated and peer reviewed pathway database
\begin_inset Quotes erd
\end_inset

 hosted and curated (mostly) by the European Bioinformatics Institute (EMBL-EBI).
 It has a web portal at 
\begin_inset CommandInset href
LatexCommand href
target "http://www.reactome.org/"

\end_inset

, and the current version is v55 released in December, 2015.
 It has an open license (Creative Commons Attribution 4.0
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
target "https://creativecommons.org/licenses/by/4.0/"

\end_inset


\end_layout

\end_inset

) for its own data and the pre-commercial license for imported 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{KEGG}
\end_layout

\end_inset

 data.
\end_layout

\begin_layout Subsection
Primary cancer cohorts
\end_layout

\begin_layout Standard
A lot of molecular information about cancer cohorts has been collected,
 analysed, and released.
 The best-known are the TCGA and ICGC.
\end_layout

\begin_layout Subsubsection
The Cancer Genome Atlas (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{TCGA}
\end_layout

\end_inset

)
\end_layout

\begin_layout Standard
The Cancer Genome Atlas is a United States-based consortium that aims to
 profile primary tumours belonging to many different cohorts on the DNA,
 RNA, protein, and epigenetic level.
 The initial release 
\begin_inset CommandInset citation
LatexCommand cite
key "The_Cancer_Genome_Atlas_Research_Network2013-bi"

\end_inset

 contained 12 tumour types, but it has grown to 35 with their June 2016
 release.
 There are many secondary portals that allow access to the TCGA data, such
 as the BROAD Firehose tool
\begin_inset Foot
status open

\begin_layout Plain Layout
https://gdac.broadinstitute.org/
\end_layout

\end_inset

 or cBioPortal 
\begin_inset CommandInset citation
LatexCommand cite
key "Gao2013-wp"

\end_inset

, the latter of which also includes data from other projects.
\end_layout

\begin_layout Subsubsection
International Cancer Genome Consortium (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{ICGC}
\end_layout

\end_inset

)
\end_layout

\begin_layout Standard
The International Cancer Genome consortium is an umbrella effort with the
 same goals, yet it incorporates many more studies from different countries
 and thus represents a superset of the TCGA data
\begin_inset CommandInset citation
LatexCommand cite
key "International_Cancer_Genome_Consortium2010-bn"

\end_inset

.
\end_layout

\begin_layout Subsection
Cancer cell line drug sensitivity resources
\end_layout

\begin_layout Standard
There are many studies measuring the drug sensitivity of different cell
 lines.
 The two biggest are the GDSC and CCLE.
\end_layout

\begin_layout Subsubsection
Genomics of Drug Sensitivity in Cancer (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{GDSC}
\end_layout

\end_inset

)
\begin_inset CommandInset label
LatexCommand label
name "subsec:GDSC"

\end_inset


\end_layout

\begin_layout Standard
The first release of the cell ling drug screening from the Cancer Genome
 Project of the Wellcome Trust Sanger Institute contained 639 cell lines
 treated with 130 cancer drugs that were in either clinical use or pre-clinical
 development, where the cell lines have also been profiled by capillary
 sequencing of 77 known oncogenes 
\begin_inset CommandInset citation
LatexCommand cite
key "Garnett2012-dk"

\end_inset

.
 The subsequent release increased this count to 1,001 cell lines and 265
 drugs, with a full molecular characterisation of cell lines comprised of
 full exome sequencing, SNP6 arrays for copy number, high-quality microarray
 gene expression, and DNA promoter methylation 
\begin_inset CommandInset citation
LatexCommand cite
key "Iorio2016-gh"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Cancer Cell Line Encyclopedia (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{CCLE}
\end_layout

\end_inset

)
\end_layout

\begin_layout Standard
The Cancer Cell Line Encyclopedia 
\begin_inset CommandInset citation
LatexCommand cite
key "Barretina2012-of"

\end_inset

 characterised the mutations of 947 human cancer cell lines along with SNP
 6.0 copy number and Affymetrix U133 Plus 2.0 array gene expression, approximately
 500 of which they treated with 24 anti-cancer compounds.
\end_layout

\begin_layout Standard
In contrast to the GDSC, they did not chose concentration ranges of the
 screened drugs in order to detect the few cell lines that are sensitive
 to a given drug, but rather a generally applicable range.
 The resulting differences compared the the GDSC caused a number of inconsistenc
ies 
\begin_inset CommandInset citation
LatexCommand cite
key "Haibe-Kains2012-ki"

\end_inset

 but they are largely resolved 
\begin_inset CommandInset citation
LatexCommand cite
key "Cancer_Cell_Line_Encyclopedia_Consortium2015-df"

\end_inset

.
\end_layout

\begin_layout Subsection
The Connectivity Map
\end_layout

\begin_layout Subsubsection
Original Connectivity Map using microarrays
\end_layout

\begin_layout Standard
The first large-scale project providing signatures of drug-perturbed gene
 expression changes in the MCF-7 cell line was the Connectivity Map 
\begin_inset CommandInset citation
LatexCommand cite
key "Lamb2006-mp"

\end_inset

.
 In comprised a total of 1,309 compounds, yet most of them were not anti-cancer
 compounds.
 It has introduced and enabled the paradigm of signature matching (section
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Signature-Matching"

\end_inset

), the method of using gene expression changes upon drug treatment to match
 either drugs with drugs for finding similarities or drugs with diseases
 for a potential treatment indication 
\begin_inset CommandInset citation
LatexCommand cite
key "Iorio2013-pv"

\end_inset

.
\end_layout

\begin_layout Subsubsection
The L1000 platform
\begin_inset CommandInset label
LatexCommand label
name "subsec:LINCS-cmap"

\end_inset


\end_layout

\begin_layout Standard
The new version of the Connectivity Map is based on 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
name{Luminex}
\end_layout

\end_inset

 beads 
\begin_inset CommandInset citation
LatexCommand cite
key "Peck2006-fa"

\end_inset

 that are able to measure about 500 transcripts.
 For the L1000 platform
\begin_inset Foot
status open

\begin_layout Plain Layout
More information is available at: 
\begin_inset CommandInset href
LatexCommand href
target "http://www.lincscloud.org/l1000/"

\end_inset


\end_layout

\end_inset

, the BROAD institute managed to put twice the amount of genes on one bead
 by scanning it in two different dilution ranges and deconvoluting them
 computationally afterwards.
 After that, they scaled the experimental readout by 80 control genes that
 are supposed to be constant across experiments, optionally infer the whole
 transcriptome from their 978 
\begin_inset Quotes eld
\end_inset

landmark
\begin_inset Quotes erd
\end_inset

 genes (projections shown in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:LINCS-projections"

\end_inset

), and compute z-scores (number of standard deviations of a perturbed condition
 over the mean of the control) for each perturbation
\begin_inset Foot
status open

\begin_layout Plain Layout
http://www.lincsproject.org/data/data-releases/
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/3.1_projections.svg
	lyxscale 50
	width 90text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Overview of number of experiments available in LINCS using cancer drugs
\end_layout

\end_inset

Overview of number of experiments available in LINCS using cancer drugs.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:LINCS-projections"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In 2015, the BROAD institute released the raw data and z-scores between
 each control- and drug-perturbed experiment for 978 oligonucleotide probes
 and a total of 1.4 million conditions in a 111 gigabyte 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
file{.gctx}
\end_layout

\end_inset

 (HDF5 and metadata) file where they projected their actual measurement
 to the full gene space using publicly available microarray data.
 At this time, no one knew about the quality of the data (the authors claimed
 it to be equal with microarrays; my own tries and conversations with other
 people using the data have indicated that it is below that).
 The main publication is still not out today (August 2016), and they refused
 to share e.g.
 the linear transformation matrix they used to obtain the projected gene
 space.
\end_layout

\begin_layout Section
Computational methods
\end_layout

\begin_layout Standard
\begin_inset CommandInset label
LatexCommand label
name "sec:Computational-methods"

\end_inset

Over the last decades and years, biology moved from an observational, qualitativ
e science to a very much quantitative one.
 This can largely be attributed to high throughput assays, led by the advance
 of DNA sequencing and followed by its derivatives as well as other approaches,
 like high-content phenotypic screening - each allowing for measuring not
 one data point, but hundreds and sometimes thousands at a time.
 The magic component in this process is automation: the bulk of the data
 generated by scientific laboratories are not longer carried out by individual
 scientists pipetting together reagents, but by machines controlled by computers
 and designed by both scientists and industry alike.
 This shift of paradigm has not only produced much more data, but arguably
 led to an increase in the quality of such data as well, by removing the
 human element (mood, ability to concentrate, etc.) from large parts of the
 outcome of an experiment.
\end_layout

\begin_layout Standard
This transformation has not only come with its benefits, but also with its
 challenges.
 Setting aside the view of some prominent scientists that each experiment
 needs to have a specific question or hypothesis in mind and that generating
 data first and using the data itself as a hypothesis generator is an inferior
 approach (as best demonstrated by Sidney Brenner's quote 
\begin_inset Quotes eld
\end_inset

low input, high throughput, not output
\begin_inset Quotes erd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Friedberg2008-cn"

\end_inset

), a biomedical scientist's skill requirements have moved from knowing,
 for instance, as many details about a given gene as possible to understanding
 how to set up reproducible assays, generate reliable data, but especially
 treating the resulting data in a way that yields biological insights.
\end_layout

\begin_layout Standard
There are two crucial parts to this: one is algorithms, that transform the
 raw data generated by a given experiment into biologically interpretable
 indications, and the second is statistics, to make sure the effect observed
 is due to the data and not due to random chance while analysing the results.
 I will outline some very successful ideas that in turn led to algorithms
 and usable software packages for investigating molecular data, both in
 terms of cancer as well as in general, in the sections of this and the
 next section.
\end_layout

\begin_layout Standard
However, let us first reconsider the goal we are trying to achieve in terms
 of this thesis as well as a lot of the related work: we ultimately want
 to improve how cancer is diagnosed and treated for patients, and those
 algorithms help us to define markers of their pathogenesis or how they
 could reap benefits from being offered a particular treatment 
\begin_inset CommandInset citation
LatexCommand cite
key "Rubio-Perez2015-ep"

\end_inset

.
 We thus want to transform the numbers reflecting the molecular data we
 have in a meaningful way so they connect to this endeavour.
\end_layout

\begin_layout Subsection
Patterns of mutations
\end_layout

\begin_layout Standard
When looking at sets of mutations instead of individual ones distinct patterns
 emerge.
 One such pattern is that there are modules that are either co-occurring
 or mutually exclusive 
\begin_inset CommandInset citation
LatexCommand cite
key "Babur2015-ap"

\end_inset

.
 In the event of co-occurring mutations, this might mean that a given mutation
 is not sufficient to obtain a certain trait and thus a second mutation
 is necessary to confer it.
 In the case of mutual exclusivity, a second mutation is not conferring
 a growth advantage after the first one arose.
 This may be due to evolutionary parsimony or a fitness defect.
 In the first case, a second mutation that inactivates, for example, an
 already inactivated tumour suppressor pathway is unlikely to happen on
 the population-level because there is no selective pressure, as the required
 trait has already been acquired by the cell.
 In the second case, the growth advantage conferred by one mutation might
 be cancelled out or counteracted by the presence of a second one, thereby
 mediating a selection growth disadvantage (fitness defect) of the cells
 carrying both mutations as opposed to either one of them.
\end_layout

\begin_layout Standard
Much focus has devoted to identifying driver mutations in different cancer
 types that, combined with oncogene addiction
\begin_inset Foot
status open

\begin_layout Plain Layout
the tendency of a transformed cell to become dependent on sustained impact
 of the lesion it first obtained, see section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:targeted-therapies"

\end_inset


\end_layout

\end_inset

 forms the basis of many targeted therapies: if you can inhibit signalling
 stemming from a mutation that drives a cancer's development and progression,
 the affected cells' growth will be severely abrogated.
\end_layout

\begin_layout Standard
The concept that a second mutation kills a cell with a given mutation has
 been termed synthetic lethality.
 It has been used to study genetic interactions in model organisms for a
 long time 
\begin_inset CommandInset citation
LatexCommand cite
key "Nijman2011-zf"

\end_inset

.
 The loss of both genes in a synthetic lethal pair is, as the name suggests,
 lethal to the organism, but the loss of each individual gene is not.
 More recently, these interactions have been used to identify probes interfering
 with RNA that are purified from a starting population 
\begin_inset CommandInset citation
LatexCommand cite
key "Cheung2011-be"

\end_inset

 and efficient computational algorithms have been developed to find those
 pairs in primary cancer data sets like the TCGA 
\begin_inset CommandInset citation
LatexCommand cite
key "Ciriello2012-hc,Gobbi2014-xz"

\end_inset

.
 These interactions can then be transformed in a network 
\begin_inset CommandInset citation
LatexCommand cite
key "Jerby-Arnon2014-fn"

\end_inset

, which can then be used to predict sensitivity of cancer cell lines to
 a certain drug treatment, as well as clinical outcome given the level of
 co-expression of its pairs.
 An example of a synthetic lethal pair that can be therapeutically exploited
 are loss of function mutations in 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
gene{BRCA1/2}
\end_layout

\end_inset

 and treatment with PARP inhibitors 
\begin_inset CommandInset citation
LatexCommand cite
key "Farmer2005-cp"

\end_inset

.
\end_layout

\begin_layout Standard
Including those sorts of analyses is an interest and future goal in my research,
 but has not contributed significant results to this thesis.
\end_layout

\begin_layout Subsection
Gene expression clustering
\end_layout

\begin_layout Standard
Cancer is known to be a heterogeneous disease, with individual tumours forming
 different subtypes even if it arose from the same tissue.
 One of the arguably most effective ways of elucidating the state of individual
 tumours and cell populations therein is quantifying its using methods such
 as microarrays or RNA sequencing.
\end_layout

\begin_layout Standard
We can use the global pattern of gene expression to identify different subtypes
 of the disease in a given tissue (or even between tissues).
 A challenge with this is is that the transcriptome could be comprised of
 up to 22,000 genes without even considering most regulatory or ribosomal
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{RNA}s
\end_layout

\end_inset

.
 This space needs to be reduced to something more manageable for inspection,
 which may reveal subgroups that have prognostic or therapeutic relevance.
 Approaches that allow for visual inspection of a high-dimensional data
 set are called dimensionality reduction techniques, while methods assigning
 the different samples to different subtypes are called clustering algorithms
 
\begin_inset CommandInset citation
LatexCommand cite
key "Xu2005-oj"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Visualising patterns in high-dimensional data
\end_layout

\begin_layout Standard
Principal Component Analysis (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{PCA}
\end_layout

\end_inset

) 
\begin_inset CommandInset citation
LatexCommand cite
key "Wold1987-se"

\end_inset

 is one of the simplest linear transformations that rotates samples in 
\begin_inset Formula $N$
\end_inset

-dimensional space (where 
\begin_inset Formula $N$
\end_inset

 is the number of observations per sample) in a way that its projection
 to 
\begin_inset Formula $M$
\end_inset

-dimensional space (the target dimensions - for interpretability usually
 two or three) maximises the variance contained in 
\begin_inset Formula $M$
\end_inset

.
 The rotation is calculated using a matrix factorisation that yields a unique
 solution.
 Its parameters provide the position of a sample in 
\begin_inset Formula $M$
\end_inset

 space where the axes are principal components, and the latter's projection
 back into 
\begin_inset Formula $N$
\end_inset

 called loadings (which represent how much of each original axis is contained
 within the new axes).
 It is important to note the meaning and interpretability of such a decompositio
n is strongly dependent on the amount of variance captured in the reduced
 space.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{PCA}
\end_layout

\end_inset

 is closely related to Singular Value Decomposition (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{SVD}
\end_layout

\end_inset

), which has applications in dimensionality reduction as well 
\begin_inset CommandInset citation
LatexCommand cite
key "Wall2003-ww"

\end_inset

.
\end_layout

\begin_layout Standard
T-distributed Stochastic Neighbour Embedding (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{t-SNE}
\end_layout

\end_inset

) 
\begin_inset CommandInset citation
LatexCommand cite
key "Van_der_Maaten2008-kt"

\end_inset

, instead of relying on the most variable global structures, visualises
 local structures in a given data set: starting from a point in space (a
 sample), additional samples are distributed in its vicinity depending on
 their distance to the original sample, as well as the other points considered
 (that are a subset of the total number of points).
 This method provides much better resolution than 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{PCA}
\end_layout

\end_inset

, but one can only trust the points neighbouring each other up to a number
 specified by the perplexity parameter.
 It has later been extended by the original author to use the Barnes-Hut
 method 
\begin_inset CommandInset citation
LatexCommand cite
key "Van_der_Maaten2013-io"

\end_inset

 that is usually used in large N-body simulation in astrophysics (and chapter
 4).
\end_layout

\begin_layout Subsubsection
Clustering
\end_layout

\begin_layout Standard
One of the simplest clustering algorithms is K-means 
\begin_inset CommandInset citation
LatexCommand cite
key "Hartigan1979-pe"

\end_inset

 that requires the number of clusters to be known 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
latin{a priori}
\end_layout

\end_inset

.
 It starts with assigning N cluster centres randomly in a given data set,
 and then assigning all samples that have a smaller distance to a given
 centre than the others to that centre.
 These assignments are iterative, which means that once the cluster centres
 have been determined and the samples assigned, the centres are updated
 to correspond to the centre of the samples each cluster is associated with.
 In turn, which samples are associated with which clusters is also updated
 after each time clusters get new samples assigned, until the process converges
 and further updating steps do not change cluster assignments anymore.
\end_layout

\begin_layout Standard
Non-Negative Matrix Factorisation (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{NMF}
\end_layout

\end_inset

) 
\begin_inset CommandInset citation
LatexCommand cite
key "Lee2001-ju"

\end_inset

 is a matrix factorisation method that decomposes the matrix 
\begin_inset Formula $V$
\end_inset

 (usually with observations in rows and samples in columns) into the matrices
 
\begin_inset Formula $W$
\end_inset

 (with samples in columns and weights for each cluster in rows) multiplied
 with the matrix 
\begin_inset Formula $H$
\end_inset

 (cluster assignment vectors in columns and samples in rows).
 It does not determine the optimal number of clusters by itself, but can
 be run with different numbers of clusters that is later evaluated using
 the cophenetic coefficient (a measure of goodness of fit of the samples
 to the cluster centres).
\end_layout

\begin_layout Standard
There are also other methods (Spectral Clustering 
\begin_inset CommandInset citation
LatexCommand cite
key "Ng2002-zs"

\end_inset

, Latent Dirichlet Allocation 
\begin_inset CommandInset citation
LatexCommand cite
key "Blei2003-oi"

\end_inset

–a modern, Bayesian method for clustering that is an active research topic.
 I have worked with 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{NMF}
\end_layout

\end_inset

 clustering to investigate cancer cell line drug sensitivity, but the results
 have not made it into this thesis.
\end_layout

\begin_layout Subsection
Gene expression signatures
\end_layout

\begin_layout Subsubsection
Signature definition
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO
\end_layout

\end_inset


\end_layout

\begin_layout Standard
pathway sigs: 
\begin_inset CommandInset citation
LatexCommand cite
key "Bild2005-tk,Gatza2010-fq,Parikh2010-uj"

\end_inset


\end_layout

\begin_layout Subsubsection
Signature Matching
\begin_inset CommandInset label
LatexCommand label
name "subsec:Signature-Matching"

\end_inset


\end_layout

\begin_layout Standard
When investigating the effect small molecules (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
latin{i.e.}
\end_layout

\end_inset

, drugs) have on a system, we might not want to look at the mechanism by
 which this happens at all, but instead rely on the changes of gene expression
 upon treatment 
\begin_inset CommandInset citation
LatexCommand cite
key "Lamb2007-dg"

\end_inset

.
 Then we could use the downstream genes that are changing as a signature
 of treatment with that drug.
 This has got two applications that have indeed been used, which are: (1)
 matching a drug's signature with another drug's signature, and if they
 are a close match but have e.g.
 different indications, suggest that each drug may be used for the other
 indication (where directionality may be limited by additional factors),
 or (2) matching a drug's signature with the inverse gene expression changes
 that a disease exhibits over normal controls, we can suggest that this
 drug may be used to counteract the effects of the disease 
\begin_inset CommandInset citation
LatexCommand cite
key "Iorio2009-ji,Pacini2013-xn"

\end_inset

, 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
latin{i.e.}
\end_layout

\end_inset

 be a potential treatment if the disease is indeed caused by the gene expression
 changes that the drug reverses.
 However, those matches should rather be seen as hypothesis generators than
 definite indications for repurposing and treatment.
 Of course, this kind of approach relies on the availability of signatures
 of the drugs we look at, or of a given drug and disease, respectively.
\end_layout

\begin_layout Subsection
Networks
\end_layout

\begin_layout Standard
An important consequence of the central dogma is that gene expression patterns
 are not randomly but hierarchically organised.
 Starting with perturbations on a cell's surface or its interior, a signal
 is propagated from its origin up to proteins that bind to DNA and change
 their expression as a response to the stimulus.
 The terminal nodes of this signal transduction are called transcription
 factors, that upon binding on the DNA mediate and direct (either in a promoting
 or in an inhibiting fashion) binding of DNA-dependent RNA polymerase (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{PolII}
\end_layout

\end_inset

) that forms a complex with available factors in order to start transcription
 of a factor's target genes 
\begin_inset CommandInset citation
LatexCommand cite
key "Watson1987-mw"

\end_inset

.
\end_layout

\begin_layout Standard
The genes transcribed upon activation of transcription factors may in turn
 be transcription factors themselves that cause increased or decreased transcrip
tion of other genes.
 These interactions between different transcription factors are usually
 referred to as a transcription factor network or gene regulatory network
 
\begin_inset CommandInset citation
LatexCommand cite
key "Bansal2007-rb"

\end_inset

.
 There are multiple ways these can be investigated: by characterising which
 transcription factors bind to which genes (either experimentally or computation
ally by looking at which sequence of nucleotides a given factor is likely
 to bind), by finding genes that change in a coordinated fashion and hypothesise
 that those might be regulated by the same set of factors, or by inferring
 which combination of which factors is required for a certain gene to be
 transcribed.
\end_layout

\begin_layout Subsubsection
Pathways and signalling
\end_layout

\begin_layout Standard
Cell signalling is deregulated in many diseases, including cancer that I
 focus on here because of the sheer wealth of available data.
 But how to best quantify the signalling activity? The closest proxy we
 have would be to quantify post-translational modifications that are known
 to confer activity.
 In the simplest case this could be a phosphate group on a certain position
 that is known to make a kinase active, that is that it in turn phosphorylates
 its downstream targets.
 But phosphorylation data, and to a lesser extent protein data in general
 is much harder to come by than sequencing data.
 Mass spectrometry and Reverse Phase Protein Arrays just do not produce
 the same clarity that a DNA sequence or RNA level provides, plus is much
 harder to generate because the technology that could do it with the same
 throughput as sequencing technologies just does not exist.
\end_layout

\begin_layout Standard
We can thus argue that computational methods are required to make statements
 about cell signalling, starting from DNA and RNA instead of protein and
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{PTM}
\end_layout

\end_inset

 data.
 The simplest approach to this is looking how much mRNA of signalling molecules
 are expressed that comprise a pathway, and designate a high expression
 a high activity and vice versa (using algorithms like Gene Set Enrichment
 Analysis 
\begin_inset CommandInset citation
LatexCommand cite
key "Subramanian2005-pd"

\end_inset

, more in chapter 2).
 This, however, is at odds with the way cell signalling works and is regulated.
 Inferring the protein levels from mRNA levels may indeed be viable 
\begin_inset CommandInset citation
LatexCommand cite
key "Gry2009-ig,Maier2009-zc"

\end_inset

, but two steps removed from the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{PTM}s
\end_layout

\end_inset

.
 Methods have been developed to address the issue of taking the expression
 level of a gene set as activity proxy by considering the structure and
 signs of the different pathway molecules, e.g.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
name{Signaling Pathway Impact Analysis}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Tarca2008-ey"

\end_inset

 or 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
name{Pathifier}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Drier2013-vn"

\end_inset

.
 They, however, do still not distinguish between expression level and activity.
 Another method, 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{PARADIGM}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Vaske2010-zn"

\end_inset

 could in theory support it, depending the pathway structure supplied for
 inference.
 Yet, the focus has never been to tell apart activity from expression.
 I elaborate on these issues further in chapter 2-4, with a possible way
 to resolve them.
\end_layout

\begin_layout Subsubsection
Binding motifs
\end_layout

\begin_layout Standard
Some, albeit not all, transcription factors prefer to bind a specific sequence
 of nucleotides that they recognize on the DNA strands, called a motif.
 Starting from binding data such as 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{ChIP-seq}
\end_layout

\end_inset

 peaks, they can be found using tools such as 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{MEME}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Bailey1995-hs"

\end_inset

 that will report different weight matrices for nucleotides around the binding
 region (which correspond to how often a given nucleotide is found in a
 given position).
 These motifs in turn can be used to scan the genome for the same or a similar
 sequence using a sliding window approach that may indicate sites where
 a transcription factor could bind but did not in the original experiment.
 Such can for instance be the case if the chromatin is too densely packed
 in a region (but may not be if the cell was in a different state or from
 a different tissue), or the binding site is occupied by another transcription
 factor blocking the binding of the one we are looking at.
 There are databases that collect and store those motifs from experimental
 data and their known and predicted binding in different cell types, such
 as 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{JASPAR}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Portales-Casamar2009-nd,Mathelier2013-mo"

\end_inset

, 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{TRANSFAC}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Matys2003-ea"

\end_inset

, or the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
name{Ensembl Regulatory Build}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Zerbino2016-mx"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Mutual Information for transcription factor networks
\end_layout

\begin_layout Standard
Another question that we might be interested in is which genes share a common
 regulator.
 In the simplest case this is a transcription factor that, upon activation,
 transcribes a set of genes in a coordinated fashion.
 Thus, we can look for genes that are expressed in a coordinated fashion
 across different conditions by calculating the mutual information of all
 gene pairs and setting a lower bound to consider.
 Further, we can prune the edges in the resulting network by postulating
 that a link between genes 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $C$
\end_inset

 is indirect if the mutual information of 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

, as well as 
\begin_inset Formula $B$
\end_inset

 and 
\begin_inset Formula $C$
\end_inset

 is higher than the one of 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $C$
\end_inset

–a concept called Data Processing Inequality.
 This is the principle of 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{ARACNE}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Margolin2006-gw"

\end_inset

 and Master Regulator Analysis (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{MRA}
\end_layout

\end_inset

), first used to identify the regulatory network in human B cells 
\begin_inset CommandInset citation
LatexCommand cite
key "Basso2005-ql"

\end_inset

.
\end_layout

\begin_layout Standard
An extension to the method proposed by the same group is to condition the
 mutual information on the expression of a modulator called 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{MINDy}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang2009-ui"

\end_inset

.
 The idea here is to look at the upper and lower third of the modulator
 expression, and calculate mutual information for both of these sets.
 Afterwards, instead of inferring the network, the authors look for the
 strongest changes in mutual information between the two subsets: if that
 is the case, the modulator can be seen as a co-factor required for transcriptio
n factor regulation.
 If a high modulator expression correlates with an increase of mutual informatio
n it will likely be activating, or inactivating in case of a decrease.
\end_layout

\begin_layout Section
Reproducibility of results
\end_layout

\begin_layout Subsection
Experimental and computational
\end_layout

\begin_layout Standard
Reproducibility of scientific experiments has recently gotten into the spotlight
 when Amgen published a high-profile study trying to independently validate
 findings of 53 findings reported by different groups in the journals 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
journal{Nature}
\end_layout

\end_inset

, 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
journal{Science}
\end_layout

\end_inset

 and 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
journal{Cell}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Begley2012-pk,Baker2016-ng"

\end_inset

.
 For 47 of the studies that they investigated, they could not obtain the
 same results that the respective authors reported.
 Needless to say, this raised some concerns about the current paradigm of
 publishing new results quickly instead of thoroughly and over-claiming
 the effect or significance of a study in order to have an article accepted
 in the top tier journals.
 Follow-up studies have pointed a part of the blame on use of different
 antibodies 
\begin_inset CommandInset citation
LatexCommand cite
key "Baker2015-vi"

\end_inset

 that did not always show the affinity and specificity to their target as
 the vendors claimed that resulted in the creation of a registry for validated
 antibodies at 
\begin_inset CommandInset citation
LatexCommand cite
key "Bradbury2015-is"

\end_inset

.
\end_layout

\begin_layout Standard
It is easy to argue that experimental reproducibility is a hard issue to
 tackle, as the potential for confounding variables is huge and a lab will
 hardly ever have the resources to account for all of them.
 In general, good study design, that is proper controls and randomisation,
 should go a long way (especially in the case of clinical trials), but even
 then, there may be confounding effects unknown to the experimenters that
 can not properly be controlled for, as has later been shown in the case
 where male vs.
 female stewards in a mouse facility produced different reactions of the
 animals, potentially influencing the results obtained from a very large
 number of studies 
\begin_inset CommandInset citation
LatexCommand cite
key "Reardon2016-bn"

\end_inset

.
\end_layout

\begin_layout Standard
Apart from experimental reproducibility, computational reproducibility should
 be an issue that is easier to tackle, because at least for deterministic
 algorithms the same input should always produce the same output using the
 same tools.
 However, this is also easier said than done because the tools will depend
 on other tools, maybe with different versions, and each version may change
 the way they treat the data to go from input to output in a slightly different
 way.
 This is especially true as computational analyses, as well as the tools
 employed, are getting more and more complex.
 However, even if the potential confounding factors are smaller than for
 experimental scientists, computational analysis also has its high-profile
 cases fraught with issues.
 The most well-known example of this are maybe Anil Potti's cancer gene
 signatures
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
target "http://retractionwatch.com/2015/11/07/its-official-anil-potti-faked-data-say-feds/"

\end_inset


\end_layout

\end_inset

 that Keith Baggerly later spent six months trying to reproduce–and failed,
 but in the process found considerable errors that later caused the original
 article to be retracted 
\begin_inset CommandInset citation
LatexCommand cite
key "Baggerly2009-xc"

\end_inset

.
\end_layout

\begin_layout Standard
To summarise, ensuring that a subsequent study has the possibility to arrive
 at the same conclusions given the same starting point, and in turn build
 on the results in a more confident way, has gotten a big enough issue to
 dedicate an introductory chapter to it.
 Since I did not perform any experiments to produce data myself, the focus
 of this chapter shall be to ensure that the results obtained by transforming
 raw (or in some cases already processed) data into other types of data,
 plots, and ultimately interpretation are reproducible in a sense that a
 person not involved in the projects could arrive at the same conclusion,
 being provided this thesis, the code used, and the technical documentation
 written in conjunction with it.
 This is especially true because the maybe best known retraction caused
 by computational irreproducibility handled a topic very similar to the
 one I investigate in this thesis: the effect of signalling pathway signatures
 of different cancers (chapter 3) and their significance (chapter 4).
\end_layout

\begin_layout Subsection
Scientific software ecosystem
\end_layout

\begin_layout Standard
With computational analyses getting more complex, it is no longer enough
 to just apply a simple statistical test for a number of observations of
 one condition vs.
 another.
 The wealth of data that has become available needs pre-processing, normalising,
 statistical analysis, and interpretation of results.
 No one scientist can perform all of these tasks completely independently,
 as some of them may detailed knowledge of all the algorithms involved,
 up to an extent that is prohibitory.
 It is thus required to package repeated steps together in higher-order
 functionality.
\end_layout

\begin_layout Standard
This is where the scientific software ecosystem comes in.
 And, to a larger extent, the ecosystem of general software.
 For instance, I want to obtain, pre-process, and normalise microarray data
 to then compute differentially expressed genes in two conditions.
 The concepts of obtain, pre-process, and normalise are well enough defined
 that I should not have to worry about their exact implementation.
 I just need to know what these concepts mean and that there is a software
 that abstracts the low-level implementation to a higher-level function
 that I can just apply.
 And, in addition, I want to script those steps together without needing
 to worry about things like the exact memory allocation in each step.
\end_layout

\begin_layout Standard
Two programming languages, along with the packages they themselves as well
 as their users provide, have been fundamental in providing a tool set that
 allows processing, exploration, and analysis of the amount of data contemporary
 experiments provide.
 These are R 
\begin_inset CommandInset citation
LatexCommand cite
key "Ihaka1996-bm"

\end_inset

 and Python 
\begin_inset CommandInset citation
LatexCommand cite
key "Van_Rossum1995-pl"

\end_inset

, along with packages hosted on 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{CRAN}
\end_layout

\end_inset

/BioConductor 
\begin_inset CommandInset citation
LatexCommand cite
key "Gentleman2004-oc"

\end_inset

 (including 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rpkg{dplyr}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Wickham2014-jy"

\end_inset

 and 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rpkg{ggplot2}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Wickham2011-qn"

\end_inset

, used extensively in the analyses I performed) and 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{PyPI}
\end_layout

\end_inset

, respectively.
 Without those tools, performing analysis like I do to obtain the results
 shown later would not be possible.
 Note that there are tools, but they do not play a similarly important role
 in contemporary data analysis.
\end_layout

\begin_layout Subsection
Reproducible workflows
\end_layout

\begin_layout Subsubsection
Keeping past versions of scripts
\end_layout

\begin_layout Standard
Requirements for analyses are going to change, and so will the scripts that
 were used to generate them.
 There is nothing that is keeping us from updating and changing them of
 course, but at times it is required to reproduce the behaviour and outcome
 of an analysis after that.
 This is where version control systems (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{VCS}
\end_layout

\end_inset

) come in.
 These are software that will keep track of all previous versions of code
 (and potentially other files as well) in case they are ever needed again.
 One of the first to be widely used was CVS 
\begin_inset CommandInset citation
LatexCommand cite
key "Thomas2003-ga"

\end_inset

, later Subversion 
\begin_inset CommandInset citation
LatexCommand cite
key "Pilato2008-bp"

\end_inset

 and now mostly Git 
\begin_inset CommandInset citation
LatexCommand cite
key "Loeliger2012-sf"

\end_inset

.
 A company that was been widely successful in promoting the use of git both
 in general and academia
\begin_inset Foot
status open

\begin_layout Plain Layout
Github has become the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
latin{de facto}
\end_layout

\end_inset

 standard in academic code sharing.
 The technology for version tracking is state of the art, the functionality
 of their website unparalleled and they offer their services to academics
 for free: 
\begin_inset CommandInset href
LatexCommand href
target "https://education.github.com/"

\end_inset


\end_layout

\end_inset

 in particular is GitHub 
\begin_inset CommandInset citation
LatexCommand cite
key "Dabbish2012-hw"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Defining workflows with a single entry point
\end_layout

\begin_layout Standard
A challenge that often is underestimated is that even when all of the code
 that was used in order to generate the result is provided, it is often
 not trivial know which script generates which part of the analysis, and
 which other scripts, analyses, or data it depends on.
 Hence it is not only important to provide the code as it is, but also informati
on on how to run it, so to not only have all the bits and pieces but a way
 to connect them to a workflow from the data to the results.
 Some tools have been proposed to manage scientific workflows like KNIME
 
\begin_inset CommandInset citation
LatexCommand cite
key "Warr2012-yd"

\end_inset

 and Taverna 
\begin_inset CommandInset citation
LatexCommand cite
key "Wolstencroft2013-eu"

\end_inset

, but they are heavy monolithic pieces of software whose use has never taken
 off.
 A simple and lightweight alternative is GNU's 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
code{make}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Stallman1991-hz,Stallman2004-ud"

\end_inset

, which was originally designed for tracking dependencies in software compilatio
n, but has been proposed to enable reproducible scientific workflows 
\begin_inset CommandInset citation
LatexCommand cite
key "Schwab2000-fk"

\end_inset

.
 It has been extensively used in the analyses because of its single entry
 point (the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
file{Makefile}
\end_layout

\end_inset

) and simple definition of dependency rules.
\end_layout

\begin_layout Subsubsection
Generating reports directly from the analysis
\end_layout

\begin_layout Standard
While the above tools take care of performing and keeping track of analyses,
 the crucial point that is missing for reproducible research is integration
 with reporting.
 A tool to do combine R code with written text and annotation (as opposed
 to technical documentation) is 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rpkg{knitr}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Xie2014-sa"

\end_inset

 that can work with either Latex or Markdown.
 For Python, the IPython notebooks 
\begin_inset CommandInset citation
LatexCommand cite
key "McKinney2012-tv"

\end_inset

 (now JupyterLab
\begin_inset Foot
status open

\begin_layout Plain Layout
http://blog.jupyter.org/2016/07/14/jupyter-lab-alpha/
\end_layout

\end_inset

) has seen wide adoption 
\begin_inset CommandInset citation
LatexCommand cite
key "Shen2014-of"

\end_inset

.
\end_layout

\begin_layout Section
Motivation and outlook
\begin_inset Note Note
status open

\begin_layout Plain Layout
this could be improved; use summary text for after 
\begin_inset Quotes eld
\end_inset

.
\begin_inset Quotes erd
\end_inset

?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Cancer sequencing projects 
\begin_inset CommandInset citation
LatexCommand cite
key "The_Cancer_Genome_Atlas_Research_Network2013-bi,International_Cancer_Genome_Consortium2010-bn"

\end_inset

 are giving us an unprecedented view on the mutational landscape of human
 cancers.
 This information is augmented by genomic and general molecular characterisation
 of cell lines and their responses to anticancer compounds 
\begin_inset CommandInset citation
LatexCommand cite
key "Garnett2012-dk,Barretina2012-of,Iorio2016-gh"

\end_inset

, or by selection viable genotypes under a selective constraint 
\begin_inset CommandInset citation
LatexCommand cite
key "Cheung2011-be"

\end_inset

.
 These projects have led us to believe that, while this landscape of genomic
 alterations is vast, they tend to occur in a limited set of pathways, often
 exhibiting a pattern different from the ones one would expect by random
 chance.
 As these modules deviate from a randomly expected distributions, it is
 commonly accepted that they represent the pattern of evolutionary adaption
 that enabled a cancer to obtain its hallmarks 
\begin_inset CommandInset citation
LatexCommand cite
key "Hanahan2000-is,Hanahan2011-he"

\end_inset

.
\end_layout

\begin_layout Standard
One of the major challenges is how to use the available molecular data in
 an efficient and reproducible manner.
 While this is relatively straightforward for mutational data (mostly used
 as binary features), it gets much more challenging for higher content readouts
 like gene expression or DNA methylation.
 Specifically, expression-derived biomarkers that were able to separate
 distinct populations in a given set of conditions have often failed to
 replicate their function once the conditions are altered.
 As DNA methylation is dynamic, it will likely offer the same challenges.
 Still, there is a tremendous amount of information that can and should
 be used to decide on the optimal treatment of patients, but most approaches
 have fallen short of that promise.
\end_layout

\begin_layout Standard
.
\end_layout

\begin_layout Standard
One way gene expression has shown promise is using global clustering to
 identify subtypes of the disease, and associating those with different
 drug response or survival outcome.
 I believe that stratifying patients in a reproducible manner should involve
 both the overall clustering of the data as well as more specific, functionally
 relevant readouts.
 An example of those functional readouts is the expression level of pre-defined
 pathway sets - mostly using the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{GSEA}
\end_layout

\end_inset

 scores - that has been reported in numerous publications, but also more
 sophisticated methods that attempt to quantify the signal flow, such as
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{SPIA}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Tarca2008-ey"

\end_inset

, 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{PARADIGM}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Vaske2010-zn"

\end_inset

, or 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
name{Pathifier}
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Drier2013-vn"

\end_inset

.
\end_layout

\begin_layout Standard
These methods, however, stand at odds with the notion that signalling in
 animal - and thus human - cells is tightly post-translationally regulated,
 since they are based on the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{mRNA}
\end_layout

\end_inset

 expression of the signalling proteins, in one way or another.
 To date, it is largely unexplored how much those pathway-expression-based
 methods are able to make statements about the signal transmission in a
 protein network.
 This is why I later followed different strategy: use a large body of publicly
 available perturbation experiments to quantify gene expression responses
 to a specified set of stimuli, and then use those genes to infer the upstream
 signal required to change their expression 
\begin_inset CommandInset citation
LatexCommand cite
key "Bild2005-tk,Gatza2010-fq,Parikh2010-uj"

\end_inset

.
 This is one way by which–only using gene expression data–I can indirectly
 observe activity instead of just 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
abbrv{mRNA}
\end_layout

\end_inset

 expression, as well as apply similar signatures for potentially synergistic
 drug combinations.
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "references"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
